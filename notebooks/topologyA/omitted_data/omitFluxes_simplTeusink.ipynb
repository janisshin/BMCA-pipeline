{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tellurium as te\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "\n",
    "import aesara.tensor as at\n",
    "import aesara\n",
    "floatX = aesara.config.floatX\n",
    "import pymc as pm\n",
    "import numpy as np\n",
    "\n",
    "import cobra\n",
    "import os\n",
    "\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../..')\n",
    "from src import antemll, util\n",
    "import emll\n",
    "from emll.aesara_utils import LeastSquaresSolve\n",
    "os.chdir('notebooks/topologyA/omitted_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Teusink_ant ='../../../data/interim/Antimony/Simplified_Teusink_yeast.ant' \n",
    "\n",
    "r = te.loada(Teusink_ant)\n",
    "r.conservedMoietyAnalysis = True\n",
    "r.steadyState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enzymes = ['e_' + i for i in r.getReactionIds()]\n",
    "internal = r.getFloatingSpeciesIds()\n",
    "external = r.getBoundarySpeciesIds()\n",
    "fluxes = ['v_' + i for i in r.getReactionIds()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaving out flux data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data01 = pd.read_csv('../../../data/interim/generated_data/simplTeusink-noReg/Simplified_Teusink_yeast_0.1.csv')[enzymes+internal+external]\n",
    "data02 = pd.read_csv('../../../data/interim/generated_data/simplTeusink-noReg/Simplified_Teusink_yeast_0.2.csv')[enzymes+internal+external]\n",
    "data03 = pd.read_csv('../../../data/interim/generated_data/simplTeusink-noReg/Simplified_Teusink_yeast_0.3.csv')[enzymes+internal+external]\n",
    "data04 = pd.read_csv('../../../data/interim/generated_data/simplTeusink-noReg/Simplified_Teusink_yeast_0.4.csv')[enzymes+internal+external]\n",
    "\n",
    "data05 = pd.read_csv('../../../data/interim/generated_data/simplTeusink-noReg/Simplified_Teusink_yeast_0.5.csv')[enzymes+internal+external]\n",
    "data10 = pd.read_csv('../../../data/interim/generated_data/simplTeusink-noReg/Simplified_Teusink_yeast_1.01.csv')[enzymes+internal+external]\n",
    "data15 = pd.read_csv('../../../data/interim/generated_data/simplTeusink-noReg/Simplified_Teusink_yeast_1.5.csv')[enzymes+internal+external]\n",
    "data3 = pd.read_csv('../../../data/interim/generated_data/simplTeusink-noReg/Simplified_Teusink_yeast_3.csv')[enzymes+internal+external]\n",
    "data5 = pd.read_csv('../../../data/interim/generated_data/simplTeusink-noReg/Simplified_Teusink_yeast_5.csv')[enzymes+internal+external]\n",
    "data7 = pd.read_csv('../../../data/interim/generated_data/simplTeusink-noReg/Simplified_Teusink_yeast_7.csv')[enzymes+internal+external]\n",
    "data100 = pd.read_csv('../../../data/interim/generated_data/simplTeusink-noReg/Simplified_Teusink_yeast_10.csv')\n",
    "v_star = data100[fluxes].iloc[0].values\n",
    "data100 = data100[enzymes+internal+external]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BMCA_obj01 = antemll.antemll(Teusink_ant, data01, filler_v_star=v_star)\n",
    "BMCA_obj02 = antemll.antemll(Teusink_ant, data02, filler_v_star=v_star)\n",
    "BMCA_obj03 = antemll.antemll(Teusink_ant, data03, filler_v_star=v_star)\n",
    "BMCA_obj04 = antemll.antemll(Teusink_ant, data04, filler_v_star=v_star)\n",
    "\n",
    "BMCA_obj05 = antemll.antemll(Teusink_ant, data05, filler_v_star=v_star)\n",
    "BMCA_obj10 = antemll.antemll(Teusink_ant, data10, filler_v_star=v_star)\n",
    "BMCA_obj15 = antemll.antemll(Teusink_ant, data15, filler_v_star=v_star)\n",
    "BMCA_obj3 = antemll.antemll(Teusink_ant, data3, filler_v_star=v_star)\n",
    "BMCA_obj5 = antemll.antemll(Teusink_ant, data5, filler_v_star=v_star)\n",
    "BMCA_obj7 = antemll.antemll(Teusink_ant, data7, filler_v_star=v_star)\n",
    "BMCA_obj100 = antemll.antemll(Teusink_ant, data100, filler_v_star=v_star)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ADVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_e_hat(BMCA_obj, v_hat_obs, x_terms, y_terms): \n",
    "    one_n = np.ones([len(x_terms.eval()),len(BMCA_obj.en)])\n",
    "    product = (v_hat_obs * (one_n + x_terms + y_terms)).eval()\n",
    "    product[product == 0 ] = 1E-6\n",
    "\n",
    "    return aesara.tensor.reciprocal(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_BayesInf(BMCA_obj, n_samp=1):\n",
    "    flux = ['v_' + i for i in r.getReactionIds()]\n",
    "        \n",
    "    known_v_inds = []\n",
    "    omitted_v_inds = []\n",
    "    for i, v in enumerate(flux):\n",
    "        if v in data100.columns:\n",
    "            known_v_inds.append(i)\n",
    "        else: \n",
    "            omitted_v_inds.append(i)\n",
    "    v_inds = np.hstack([known_v_inds, omitted_v_inds]).argsort()\n",
    "\n",
    "    with pm.Model() as pymc_model:\n",
    "\n",
    "        # Initialize elasticities\n",
    "        Ex_t = pm.Deterministic('Ex', util.initialize_elasticity(BMCA_obj.Ex.to_numpy(), name='Ex'))\n",
    "        Ey_t = pm.Deterministic('Ey', util.initialize_elasticity(BMCA_obj.Ey.to_numpy(), name='Ey'))\n",
    "        \n",
    "        # flux priors\n",
    "        v_measured = pm.Normal('v_measured', mu=0, sigma=0.1, observed=BMCA_obj.vn.T)\n",
    "        v_unmeasured = pm.Normal('v_unmeasured', mu=0, sigma=1, shape=(len(omitted_v_inds), len(BMCA_obj.vn)))\n",
    "\n",
    "        v_t = at.concatenate([v_measured, v_unmeasured], axis=0)[v_inds, :]\n",
    "        pm.Deterministic('v_t', v_t)\n",
    "\n",
    "        chi_t = pm.Normal('chi_t', mu=0, sigma=0.5, observed=BMCA_obj.xn.T)\n",
    "        y_t = pm.Normal('y_t', mu=0, sigma=0.5, observed=BMCA_obj.yn.T)\n",
    "\n",
    "        #### NEED TO ADD fitting equation here\n",
    "        e_ss = calculate_e_hat(BMCA_obj, v_t, Ex_t@chi_t, Ey_t@y_t)\n",
    "        e_t = pm.Normal('e_t', mu=e_ss, sigma=1, observed=BMCA_obj.en.squeeze().T)\n",
    "\n",
    "        N_ITERATIONS = 45000\n",
    "\n",
    "        advi = pm.ADVI()\n",
    "        tracker = pm.callbacks.Tracker(\n",
    "            mean = advi.approx.mean.eval,\n",
    "            std = advi.approx.std.eval\n",
    "        )\n",
    "        approx = advi.fit(\n",
    "            n=N_ITERATIONS, \n",
    "            callbacks = [tracker],\n",
    "            obj_optimizer=pm.adagrad_window(learning_rate=5E-3), \n",
    "            total_grad_norm_constraint=0.7,\n",
    "            obj_n_mc=1)\n",
    "        \n",
    "    with sns.plotting_context('notebook', font_scale=1.2):\n",
    "\n",
    "        fig = plt.figure(figsize=(5,4))\n",
    "        plt.plot(approx.hist + 30, '.', rasterized=True, ms=1)\n",
    "        # plt.ylim([-1E1, 1E3])\n",
    "        plt.xlim([0, N_ITERATIONS])\n",
    "        sns.despine(trim=True, offset=10)\n",
    "\n",
    "        plt.ylabel('-ELBO')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.title('in vitro ADVI convergence')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    if n_samp > 1:\n",
    "        samples = []\n",
    "        for i in range(n_samp): \n",
    "            samples.append(approx.sample(draws=1000))\n",
    "        return samples\n",
    "    else:\n",
    "        return approx.sample(draws=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace01 = run_BayesInf(BMCA_obj01, n_samp=3)\n",
    "trace02 = run_BayesInf(BMCA_obj02, n_samp=3)\n",
    "trace03 = run_BayesInf(BMCA_obj03, n_samp=3)\n",
    "trace04 = run_BayesInf(BMCA_obj04, n_samp=3)\n",
    "\n",
    "trace05 = run_BayesInf(BMCA_obj05, n_samp=3)\n",
    "trace10 = run_BayesInf(BMCA_obj10, n_samp=3)\n",
    "trace15 = run_BayesInf(BMCA_obj15, n_samp=3)\n",
    "trace3 = run_BayesInf(BMCA_obj3, n_samp=3)\n",
    "trace5 = run_BayesInf(BMCA_obj5, n_samp=3)\n",
    "trace7 = run_BayesInf(BMCA_obj7, n_samp=3)\n",
    "trace100 = run_BayesInf(BMCA_obj100, n_samp=3)\n",
    "#326 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting ADVI results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "def get_az_mean(traces): \n",
    "    trace_means = []\n",
    "    for t in traces: \n",
    "        Ex_mean = az.summary(t)['mean'].reset_index()\n",
    "        Ex_mean.columns = ['elasticity', 'mean']\n",
    "        Ex_mean = Ex_mean[Ex_mean.elasticity.str.contains(\"Ex\\[\")]['mean'].values.flatten().reshape((-1,1))\n",
    "        trace_means.append(Ex_mean)\n",
    "    Ex = np.concatenate(trace_means, axis=1)\n",
    "    return np.mean(Ex, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_Ex01_advi = get_az_mean(trace01)\n",
    "med_Ex02_advi = get_az_mean(trace02)\n",
    "med_Ex03_advi = get_az_mean(trace03)\n",
    "med_Ex04_advi = get_az_mean(trace04)\n",
    "\n",
    "med_Ex05_advi = get_az_mean(trace05)\n",
    "med_Ex10_advi = get_az_mean(trace10)\n",
    "med_Ex15_advi = get_az_mean(trace15)\n",
    "med_Ex3_advi = get_az_mean(trace3)\n",
    "med_Ex5_advi = get_az_mean(trace5)\n",
    "med_Ex7_advi = get_az_mean(trace7)\n",
    "med_Ex100_advi = get_az_mean(trace100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt01_0 = (trace01[0]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt01_1 = (trace01[1]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt01_2 = (trace01[2]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt01 = np.concatenate([vt01_0, vt01_1, vt01_2])\n",
    "med_vt_advi_01 = np.median(vt01, axis=0).transpose()\n",
    "\n",
    "vt02_0 = (trace02[0]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt02_1 = (trace02[1]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt02_2 = (trace02[2]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt02 = np.concatenate([vt02_0, vt02_1, vt02_2])\n",
    "med_vt_advi_02 = np.median(vt02, axis=0).transpose()\n",
    "\n",
    "vt03_0 = (trace03[0]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt03_1 = (trace03[1]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt03_2 = (trace03[2]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt03 = np.concatenate([vt03_0, vt03_1, vt03_2])\n",
    "med_vt_advi_03 = np.median(vt03, axis=0).transpose()\n",
    "\n",
    "vt04_0 = (trace04[0]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt04_1 = (trace04[1]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt04_2 = (trace04[2]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt04 = np.concatenate([vt04_0, vt04_1, vt04_2])\n",
    "med_vt_advi_04 = np.median(vt04, axis=0).transpose()\n",
    "\n",
    "vt05_0 = (trace05[0]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt05_1 = (trace05[1]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt05_2 = (trace05[2]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt05 = np.concatenate([vt05_0, vt05_1, vt05_2])\n",
    "med_vt_advi_05 = np.median(vt05, axis=0).transpose()\n",
    "\n",
    "vt10_0 = (trace10[0]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt10_1 = (trace10[1]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt10_2 = (trace10[2]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt10 = np.concatenate([vt10_0, vt10_1, vt10_2])\n",
    "med_vt_advi_10 = np.median(vt10, axis=0).transpose()\n",
    "\n",
    "vt15_0 = (trace15[0]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt15_1 = (trace15[1]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt15_2 = (trace15[2]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt15 = np.concatenate([vt15_0, vt15_1, vt15_2])\n",
    "med_vt_advi_15 = np.median(vt15, axis=0).transpose()\n",
    "\n",
    "vt3_0 = (trace3[0]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt3_1 = (trace3[1]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt3_2 = (trace3[2]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt3 = np.concatenate([vt3_0, vt3_1, vt3_2])\n",
    "med_vt_advi_3 = np.median(vt3, axis=0).transpose()\n",
    "\n",
    "vt5_0 = (trace5[0]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt5_1 = (trace5[1]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt5_2 = (trace5[2]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt5 = np.concatenate([vt5_0, vt5_1, vt5_2])\n",
    "med_vt_advi_5 = np.median(vt5, axis=0).transpose()\n",
    "\n",
    "vt7_0 = (trace7[0]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt7_1 = (trace7[1]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt7_2 = (trace7[2]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt7 = np.concatenate([vt7_0, vt7_1, vt7_2])\n",
    "med_vt_advi_7 = np.median(vt7, axis=0).transpose()\n",
    "\n",
    "vt100_0 = (trace100[0]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt100_1 = (trace100[1]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt100_2 = (trace100[2]['posterior']['v_t']).to_numpy().squeeze()\n",
    "vt100 = np.concatenate([vt100_0, vt100_1, vt100_2])\n",
    "med_vt_advi_100 = np.median(vt100, axis=0).transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating FCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtFCC = pd.DataFrame(r.getScaledFluxControlCoefficientMatrix(), index=r.getReactionIds(), columns=r.getReactionIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_CCs(BMCA_obj, Ex, med_vt_advi):\n",
    "    BMCA_obj.vn[BMCA_obj.vn == 0] = 1e-6\n",
    "    \n",
    "    a = np.diag(BMCA_obj.en.values / med_vt_advi)# BMCA_obj.vn.values)\n",
    "    a = np.diag(a)\n",
    "    a = a[np.newaxis,:].repeat(3000, axis=0)\n",
    "\n",
    "    Ex_ss = a @ Ex\n",
    "    As = BMCA_obj.N @ np.diag(BMCA_obj.v_star) @ Ex_ss\n",
    "    bs = BMCA_obj.N @ np.diag(BMCA_obj.v_star)\n",
    "    bs = bs[np.newaxis, :].repeat(3000, axis=0)\n",
    "    \n",
    "    As = at.as_tensor_variable(As)\n",
    "    bs = at.as_tensor_variable(bs)\n",
    "\n",
    "    def solve_aesara(A, b):\n",
    "        rsolve_op = LeastSquaresSolve()\n",
    "        return rsolve_op(A, b).squeeze()\n",
    "\n",
    "    CCC, _ = aesara.scan(lambda A, b: solve_aesara(A, b),\n",
    "                        sequences=[As, bs], strict=True)\n",
    "\n",
    "    identity = np.eye(len(BMCA_obj.N.T))\n",
    "    identity = identity[np.newaxis,:].repeat(3000, axis=0)\n",
    "    \n",
    "    FCC = (Ex_ss @ CCC.eval()) + identity\n",
    "    \n",
    "    return FCC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postFCC01 = estimate_CCs(BMCA_obj01, med_Ex01_advi.reshape((16,11)), med_vt_advi_01)\n",
    "postFCC02 = estimate_CCs(BMCA_obj02, med_Ex02_advi.reshape((16,11)), med_vt_advi_02)\n",
    "postFCC03 = estimate_CCs(BMCA_obj03, med_Ex03_advi.reshape((16,11)), med_vt_advi_03)\n",
    "postFCC04 = estimate_CCs(BMCA_obj04, med_Ex04_advi.reshape((16,11)), med_vt_advi_04)\n",
    "\n",
    "postFCC05 = estimate_CCs(BMCA_obj05, med_Ex05_advi.reshape((16,11)), med_vt_advi_05)\n",
    "postFCC10 = estimate_CCs(BMCA_obj10, med_Ex10_advi.reshape((16,11)), med_vt_advi_10)\n",
    "postFCC15 = estimate_CCs(BMCA_obj15, med_Ex15_advi.reshape((16,11)), med_vt_advi_15)\n",
    "postFCC3 = estimate_CCs(BMCA_obj3, med_Ex3_advi.reshape((16,11)), med_vt_advi_3)\n",
    "postFCC5 = estimate_CCs(BMCA_obj5, med_Ex5_advi.reshape((16,11)), med_vt_advi_5)\n",
    "postFCC7 = estimate_CCs(BMCA_obj7, med_Ex7_advi.reshape((16,11)), med_vt_advi_7)\n",
    "postFCC100 = estimate_CCs(BMCA_obj100, med_Ex100_advi.reshape((16,11)), med_vt_advi_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn_FCCs = [postFCC01, postFCC02, postFCC03, postFCC04, postFCC05, postFCC10, postFCC15, postFCC3, postFCC5, postFCC7, postFCC100]\n",
    "pt_labels = ['0.1x', '0.2x', '0.3x', '0.4x','0.5x', '1.01x', '1.5x', '3x', '5x', '7x', '10x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_FCC_df(postFCC, label):\n",
    "    dfs=[]\n",
    "    \n",
    "    for idx, rxn in enumerate(r.getReactionIds()):\n",
    "        # negativity applied here\n",
    "        df = -pd.DataFrame(postFCC[:,idx,:], columns=r.getReactionIds())\n",
    "        df['pt_rxn']=[rxn]*len(df)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    w = pd.concat(dfs)\n",
    "    w['pt_str']=[label]*len(w)\n",
    "    return w\n",
    "\n",
    "prd_FCCs = pd.concat([append_FCC_df(rxn_FCCs[i], pt_labels[i]) for i in range(len(rxn_FCCs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medPrdFCCs = pd.pivot_table(prd_FCCs, index=['pt_rxn','pt_str'], aggfunc='median', sort=False)\n",
    "# medPrdFCCs.loc['vGLK']\n",
    "medPrdFCCs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing the averaged differences between ground truth and predicted distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each reaction that can be perturbed\n",
    "for rxn in r.getReactionIds():\n",
    "    # locate the applicable rows in the medPrdFCCs df\n",
    "    a = medPrdFCCs.loc[rxn]\n",
    "    gtvals = np.repeat(gtFCC[rxn].values, repeats=len(pt_labels), axis=0).reshape((len(pt_labels), -1))\n",
    "    # calculate the absolute difference...\n",
    "    absDifs = a - gtvals\n",
    "    # and the relative difference\n",
    "    relDifs = absDifs/gtvals\n",
    "    \n",
    "    # plot both graphs \n",
    "    f1 = plt.figure(figsize=(16, 10))\n",
    "    absDifs.T.plot(kind='bar')\n",
    "    # alternate color each group of reactions so it is easier to see\n",
    "    for i in range(8):\n",
    "            plt.axvspan(2*i + 0.5, 2*i + 1.5, alpha=0.1)\n",
    "    plt.axhline(0, c='gray')\n",
    "    plt.ylim((-1,1))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title(f'ADVI predictions for {rxn} FCCs given all data--absDifs')\n",
    "\n",
    "    \"\"\"\n",
    "    f2 = plt.figure(figsize=(16, 10))\n",
    "    relDifs.T.plot(kind='bar')\n",
    "    # alternate color each group of reactions so it is easier to see\n",
    "    for i in range(8):\n",
    "            plt.axvspan(2*i + 0.5, 2*i + 1.5, alpha=0.1)\n",
    "    plt.axhline(0, c='gray')\n",
    "    plt.ylim((-10,10))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title(f'ADVI predictions for {rxn} FCCs given all data--relDifs')\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating FCC ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ground truth FCC rankings\n",
    "\n",
    "gtFCC=pd.DataFrame(r.getScaledFluxControlCoefficientMatrix(), columns=r.getReactionIds(), index=r.getReactionIds()).abs()\n",
    "m1 = gtFCC.index.values[:, None] == gtFCC.columns.values\n",
    "gtFCC = pd.DataFrame(np.select([m1], [float('Nan')], gtFCC), columns=gtFCC.columns, index=gtFCC.index)\n",
    "gtFCC_rankings= gtFCC.rank(axis=1, ascending=False, na_option='keep')\n",
    "\n",
    "a = gtFCC_rankings.loc['vADH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### via Spearman rank coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_FCC_med_rankings(postFCC, reaction='vADH'):\n",
    "    postFCC_med=pd.DataFrame(np.median(postFCC, axis=0), columns=r.getReactionIds(), index=r.getReactionIds()).abs()\n",
    "    m1 = postFCC_med.index.values[:, None] == postFCC_med.columns.values\n",
    "    postFCC = pd.DataFrame(np.select([m1], [float('Nan')], postFCC_med), columns=postFCC_med.columns, index=postFCC_med.index)\n",
    "    postFCC_rankings= postFCC.rank(axis=1, ascending=False, na_option='keep')\n",
    "    \n",
    "    return postFCC_rankings.loc[reaction]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_coefficients = []\n",
    "b_list = []\n",
    "for FCC in rxn_FCCs:\n",
    "    b = calculate_FCC_med_rankings(FCC)\n",
    "    b_list.append(b)\n",
    "    spearman_coefficients.append(stats.spearmanr(a.dropna().values, b.dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(pt_labels, [i[0] for i in spearman_coefficients], alpha=0.5, color='r')\n",
    "plt.grid()\n",
    "\n",
    "for i, txt in enumerate([i[1].round(3) for i in spearman_coefficients]):\n",
    "    plt.annotate(txt, (pt_labels[i], [i[0] for i in spearman_coefficients][i]), ha='center')\n",
    "\n",
    "plt.title(\"Spearman rank correlation coefficients by perturbation strength\")\n",
    "plt.xlabel('perturbation level')\n",
    "plt.ylabel('Spearman $\\it{r}$')\n",
    "plt.ylim((0, 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(pt_labels, [i[0] for i in spearman_coefficients], alpha=0.5, color='r')\n",
    "plt.grid()\n",
    "\n",
    "for i, txt in enumerate([i[1].round(3) for i in spearman_coefficients]):\n",
    "    plt.annotate(txt, (pt_labels[i], [i[0] for i in spearman_coefficients][i]), ha='center')\n",
    "\n",
    "plt.title(\"Spearman rank correlation coefficients by perturbation strength\")\n",
    "plt.xlabel('perturbation level')\n",
    "plt.ylabel('Spearman $\\it{r}$')\n",
    "plt.ylim((-1, 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pt_labels, [i[0] for i in spearman_coefficients],'ro')\n",
    "plt.grid()\n",
    "\n",
    "for i, txt in enumerate([i[1].round(3) for i in spearman_coefficients]):\n",
    "    plt.annotate(txt, (pt_labels[i], [i[0] for i in spearman_coefficients][i]), ha='center')\n",
    "\n",
    "plt.title(\"Spearman rank correlation coefficients by perturbation strength\")\n",
    "plt.xlabel('perturbation level')\n",
    "plt.ylabel('Spearman $\\it{r}$')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluating top five rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_b_list = [b.sort_values().reset_index().set_index('vADH') for b in b_list]\n",
    "q = pd.concat(ranked_b_list, axis=1)\n",
    "q['gt'] = a.sort_values().reset_index().set_index('vADH')\n",
    "q.columns = pt_labels + ['gt']\n",
    "q = q[['gt'] + pt_labels]\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.to_csv('omitFluxes_simplTeusink_rankings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gayles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
