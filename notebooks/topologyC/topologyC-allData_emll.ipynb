{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "te.__version__ # pytensor5 '2.2.4.1'\n",
    "te.__version__ # gayles '2.2.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tellurium as te\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import arviz as az\n",
    "\n",
    "import pytensor.tensor as at\n",
    "import pytensor\n",
    "floatX = pytensor.config.floatX\n",
    "import pymc as pm\n",
    "import numpy as np\n",
    "\n",
    "import cobra\n",
    "import os\n",
    "\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "import math\n",
    "\n",
    "import cloudpickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emll\n",
    "from emll.pytensor_utils import LeastSquaresSolve"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "os.chdir('..')\n",
    "from src import antemll, util\n",
    "os.chdir('notebooks')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "ant = '../models/antimony/TopologyC.ant'  \n",
    "r = te.loada(ant)\n",
    "r.conservedMoietyAnalysis = True\n",
    "r.steadyState()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "data_file = '../data/TopologyC_1.5.csv'\n",
    "BMCA_obj = antemll.antemll(ant, data_file, cobra_sbml='../models/sbml/TopologyC_cobra.xml')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "with gzip.open(\"topologyC_BMCA_obj.pgz\", \"wb\") as f:\n",
    "            cloudpickle.dump(\n",
    "                {\n",
    "                \"BMCA_obj\": BMCA_obj\n",
    "                },\n",
    "                f,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ADVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = emll.LinLogLeastNorm(BMCA_obj.N, BMCA_obj.Ex.to_numpy(), BMCA_obj.Ey.to_numpy(), BMCA_obj.v_star, driver='gelsy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as pymc_model:\n",
    "    \n",
    "    # Initialize elasticities\n",
    "    # Ex and Ey have to be shape (rxns, mets)\n",
    "    Ex_t = pm.Deterministic('Ex', emll.util.initialize_elasticity(BMCA_obj.Ex.to_numpy().T, 'Ex', b=0.05, sigma=1, alpha=5))\n",
    "    Ey_t = pm.Deterministic('Ey', emll.util.initialize_elasticity(BMCA_obj.Ey.to_numpy().T, 'Ey', b=0.05, sigma=1, alpha=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pymc_model:\n",
    "    trace_prior = pm.sample_prior_predictive()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "with pymc_model:\n",
    "\n",
    "    e_obs = pm.Normal('e_obs', mu=1, sigma=1, observed=BMCA_obj.en.T)\n",
    "    y_obs = pm.Normal('y_obs', mu=0, sigma=10, observed=BMCA_obj.yn.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pymc_model:\n",
    "        \n",
    "    # Error priors. \n",
    "    v_err = pm.HalfNormal('v_error', sigma=0.05, initval=.1)\n",
    "    x_err = pm.HalfNormal('x_error', sigma=0.05, initval=.1)\n",
    "\n",
    "    # Calculate steady-state concentrations and fluxes from elasticities\n",
    "    chi_ss, v_hat_ss = ll.steady_state_pytensor(Ex_t, Ey_t, BMCA_obj.en.values, BMCA_obj.yn.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pymc_model:\n",
    "    # Error distributions for observed steady-state concentrations and fluxes\n",
    "    chi_obs = pm.Normal('chi_obs', mu=chi_ss, sigma=x_err, observed=BMCA_obj.xn.values)\n",
    "    v_hat_obs = pm.Normal('v_hat_obs', mu=v_hat_ss[:, 0].squeeze(),\n",
    "                          sigma=v_err, observed=BMCA_obj.vn.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pymc_model:\n",
    "    advi = pm.ADVI()\n",
    "    tracker = pm.callbacks.Tracker(\n",
    "        mean = advi.approx.mean.eval,\n",
    "        std = advi.approx.std.eval\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITERATIONS = 50000\n",
    "with pymc_model:\n",
    "    approx = advi.fit(\n",
    "        n= N_ITERATIONS, \n",
    "        callbacks = [tracker],\n",
    "        obj_optimizer=pm.adagrad_window(learning_rate=5E-3), \n",
    "        total_grad_norm_constraint=0.7,\n",
    "        obj_n_mc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"topologyC_allData_traces.pgz\", \"wb\") as f:\n",
    "            cloudpickle.dump(\n",
    "                {\n",
    "                \"approx\":approx\n",
    "                },\n",
    "                f,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picklefolder = '../../../data/results/tracePickles/'\n",
    "picklefolder = '../../data/results/tracePickles/'\n",
    "with gzip.open(picklefolder + 'topologyC_allData_traces_100.pgz', \"rb\") as f:\n",
    "    traces = cloudpickle.load(f, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace05=traces['trace05']\n",
    "trace15=traces['trace15']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ex05_advi = util.get_az_summary(trace05)\n",
    "Ex15_advi = util.get_az_summary(trace15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et05 = (trace05['posterior']['log_en_t']).to_numpy().squeeze()\n",
    "et15 = (trace15['posterior']['log_en_t']).to_numpy().squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et05_mean = az.summary(trace05)['mean'].reset_index()\n",
    "et05_mean.columns = ['elasticity', 'mean']\n",
    "et05_mean = et05_mean[et05_mean.elasticity.str.contains(\"log_en_t\")]['mean'].values.flatten().reshape((-1,1))\n",
    "et05_mean = np.mean(et05_mean, axis=1)\n",
    "et05_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BMCA_obj05.vn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "68*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et15_mean = az.summary(trace15)['mean'].reset_index()\n",
    "et15_mean.columns = ['elasticity', 'mean']\n",
    "et15_mean = et15_mean[et15_mean.elasticity.str.contains(\"log_en_t\")]['mean'].values.flatten().reshape((-1,1))\n",
    "et15_mean = np.mean(et15_mean, axis=1)\n",
    "et15_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticity_values = np.column_stack([r.getScaledElasticityMatrix().flatten(),\n",
    "                                Ex05_advi, Ex15_advi])\n",
    "\n",
    "elasticities_df = pd.DataFrame(elasticity_values, columns=['gt']+pt_labels,\n",
    "                               index=[i + '_' + ii for i in r.getReactionIds() for ii in r.getFloatingSpeciesIds()])\n",
    "# elasticities_df.to_csv('topologyA_allData_elasticities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_slopes = [round(util.calculate_slope(elasticities_df['gt'], elasticities_df[i])[0],3) for i in pt_labels]\n",
    "e_intercepts = [round(util.calculate_slope(elasticities_df['gt'], elasticities_df[i])[1],3) for i in pt_labels]\n",
    "e_r2s = [round(util.calculate_slope(elasticities_df['gt'], elasticities_df[i])[2],3) for i in pt_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "\n",
    "plt.scatter(elasticities_df['gt'], elasticities_df['0.5x'], alpha=0.4, label='0.5x', zorder=10)\n",
    "plt.scatter(elasticities_df['gt'], elasticities_df['1.5x'], alpha=0.4, label='1.5x')\n",
    "\n",
    "plt.axline([0, 0], [1, 1], c='gray', linestyle='dashed', zorder=1, linewidth=3)\n",
    "plt.grid(True, which='both', axis='both', zorder=0)\n",
    "plt.xlabel('ground truth elasticity values', size=14)\n",
    "plt.ylabel('predicted elasticity values, $\\it{r}$', size=14)\n",
    "# plt.title('Parity plot of elasticity values for various \\nenzyme perturbation strengthsâ€”CRISPRi', size=20)\n",
    "plt.title('allData noReg CRISPRi', size=20)\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "\n",
    "left_adjust = 14\n",
    "line_spacing = 0.6\n",
    "slope_start = 0.5\n",
    "r2_start = slope_start-(7*line_spacing)\n",
    "\n",
    "plt.text(left_adjust, slope_start, \"slopes\")\n",
    "for i, label in enumerate(pt_labels[0:5]):\n",
    "    plt.text(left_adjust, (slope_start-line_spacing)-(i*line_spacing), f'{label}: {e_slopes[i]}')\n",
    "\n",
    "plt.text(left_adjust, r2_start, 'R-squared')\n",
    "for i, label in enumerate(pt_labels[0:5]):\n",
    "    plt.text(left_adjust, (r2_start-line_spacing)-(i*line_spacing), f'{label}: {e_r2s[i]}')\n",
    "\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "for i in range(2):\n",
    "    plt.axline((0, e_intercepts[i]), slope=e_slopes[i], linestyle='--', alpha=0.6, color=colors[i], zorder=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.axes().set_aspect('equal', 'datalim')\n",
    "\n",
    "plt.ylim(-10,10)\n",
    "plt.xlim(-10,10)\n",
    "\n",
    "plt.scatter(elasticities_df['gt'], elasticities_df['0.5x'], alpha=0.4, label='0.5x', zorder=10)\n",
    "plt.scatter(elasticities_df['gt'], elasticities_df['1.5x'], alpha=0.4, label='1.5x')\n",
    "\n",
    "plt.axline([0, 0], [1, 1], c='gray', linestyle='dashed', zorder=1, linewidth=3)\n",
    "plt.grid(True, which='both', axis='both', zorder=0)\n",
    "plt.xlabel('ground truth elasticity values', size=14)\n",
    "plt.ylabel('predicted elasticity values, $\\it{r}$', size=14)\n",
    "# plt.title('Parity plot of elasticity values for various \\nenzyme perturbation strengthsâ€”CRISPRi', size=20)\n",
    "plt.title('allData noReg CRISPRi', size=20)\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "\n",
    "left_adjust = 11\n",
    "line_spacing = 0.8\n",
    "slope_start = 0.5\n",
    "r2_start = slope_start-(7*line_spacing)\n",
    "\n",
    "plt.text(left_adjust, slope_start, \"slopes\")\n",
    "for i, label in enumerate(pt_labels[0:5]):\n",
    "    plt.text(left_adjust, (slope_start-line_spacing)-(i*line_spacing), f'{label}: {e_slopes[i]}')\n",
    "\n",
    "plt.text(left_adjust, r2_start, 'R-squared')\n",
    "for i, label in enumerate(pt_labels[0:5]):\n",
    "    plt.text(left_adjust, (r2_start-line_spacing)-(i*line_spacing), f'{label}: {e_r2s[i]}')\n",
    "\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "for i in range(2):\n",
    "    plt.axline((0, e_intercepts[i]), slope=e_slopes[i], linestyle='--', alpha=0.6, color=colors[i], zorder=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out MAE for each perturbation strength\n",
    "MAE = abs(elasticities_df.sub(elasticities_df['gt'], axis=0)).sum()\n",
    "# MAE.to_csv('topologyC_allData_MAE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating FCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtFCC = pd.DataFrame(r.getScaledFluxControlCoefficientMatrix(), index=r.getReactionIds(), columns=r.getReactionIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_CCs(BMCA_obj, Ex, et):\n",
    "    BMCA_obj.vn[BMCA_obj.vn == 0] = 1e-6\n",
    "    \n",
    "    a = np.diag(et / BMCA_obj.vn.values)\n",
    "    a = np.diag(a)\n",
    "    a = a[np.newaxis,:].repeat(1000, axis=0)\n",
    "\n",
    "    Ex_ss = a @ Ex\n",
    "    As = BMCA_obj.N @ np.diag(BMCA_obj.v_star) @ Ex_ss\n",
    "    bs = BMCA_obj.N @ np.diag(BMCA_obj.v_star)\n",
    "    bs = bs[np.newaxis, :].repeat(1000, axis=0)\n",
    "    \n",
    "    As = at.as_tensor_variable(As)\n",
    "    bs = at.as_tensor_variable(bs)\n",
    "\n",
    "    def solve_pytensor(A, b):\n",
    "        rsolve_op = LeastSquaresSolve()\n",
    "        return rsolve_op(A, b).squeeze()\n",
    "\n",
    "    CCC, _ = pytensor.scan(lambda A, b: solve_pytensor(A, b),\n",
    "                        sequences=[As, bs], strict=True)\n",
    "\n",
    "    identity = np.eye(len(BMCA_obj.N.T))\n",
    "    identity = identity[np.newaxis,:].repeat(1000, axis=0)\n",
    "    \n",
    "    FCC = (Ex_ss @ CCC.eval()) + identity\n",
    "    \n",
    "    # return CCC.eval(), FCC\n",
    "    return FCC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postFCC05 = estimate_CCs(BMCA_obj05, Ex05_advi.reshape((19,13)), et05)\n",
    "postFCC15 = estimate_CCs(BMCA_obj15, Ex15_advi.reshape((19,13)), et05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn_FCCs = [postFCC05, postFCC15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_FCC_df(postFCC, label):\n",
    "    dfs=[]\n",
    "    \n",
    "    for idx, rxn in enumerate(r.getReactionIds()):\n",
    "        # negativity applied here\n",
    "        df = -pd.DataFrame(postFCC[:,idx,:], columns=r.getReactionIds())\n",
    "        df['pt_rxn']=[rxn]*len(df)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    w = pd.concat(dfs)\n",
    "    w['pt_str']=[label]*len(w)\n",
    "    return w\n",
    "\n",
    "prd_FCCs = pd.concat([append_FCC_df(rxn_FCCs[i], pt_labels[i]) for i in range(len(rxn_FCCs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medPrdFCCs = pd.pivot_table(prd_FCCs, index=['pt_rxn','pt_str'], aggfunc='median', sort=False)\n",
    "medPrdFCCs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing the averaged differences between ground truth and predicted distributions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# for each reaction that can be perturbed\n",
    "for rxn in r.getReactionIds():\n",
    "    # locate the applicable rows in the medPrdFCCs df\n",
    "    a = medPrdFCCs.loc[rxn]\n",
    "    gtvals = np.repeat(gtFCC[rxn].values, repeats=len(pt_labels), axis=0).reshape((len(pt_labels), -1))\n",
    "    # calculate the absolute difference...\n",
    "    absDifs = a - gtvals\n",
    "    # and the relative difference\n",
    "    relDifs = absDifs/gtvals\n",
    "    \n",
    "    # plot both graphs \n",
    "    f1 = plt.figure(figsize=(16, 10))\n",
    "    absDifs.T.plot(kind='bar')\n",
    "    # alternate color each group of reactions so it is easier to see\n",
    "    for i in range(8):\n",
    "            plt.axvspan(2*i + 0.5, 2*i + 1.5, alpha=0.1)\n",
    "    plt.axhline(0, c='gray')\n",
    "    plt.ylim((-1,1))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title(f'ADVI predictions for {rxn} FCCs given all data--absDifs')\n",
    "\"\"\"\n",
    "    f2 = plt.figure(figsize=(16, 10))\n",
    "    relDifs.T.plot(kind='bar')\n",
    "    # alternate color each group of reactions so it is easier to see\n",
    "    for i in range(8):\n",
    "            plt.axvspan(2*i + 0.5, 2*i + 1.5, alpha=0.1)\n",
    "    plt.axhline(0, c='gray')\n",
    "    plt.ylim((-10,10))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title(f'ADVI predictions for {rxn} FCCs given all data--relDifs')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating FCC ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ground truth FCC rankings for vADH\n",
    "\n",
    "gtFCC=pd.DataFrame(r.getScaledFluxControlCoefficientMatrix(), columns=r.getReactionIds(), index=r.getReactionIds()).abs()\n",
    "m1 = gtFCC.index.values[:, None] == gtFCC.columns.values\n",
    "gtFCC = pd.DataFrame(np.select([m1], [float('Nan')], gtFCC), columns=gtFCC.columns, index=gtFCC.index)\n",
    "gtFCC_rankings= gtFCC.rank(axis=1, ascending=False, na_option='keep')\n",
    "\n",
    "a = gtFCC_rankings.loc['v19']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### via Spearman rank coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_FCC_med_rankings(postFCC, reaction='v19'):\n",
    "    postFCC_med=pd.DataFrame(np.median(postFCC, axis=0), columns=r.getReactionIds(), index=r.getReactionIds()).abs()\n",
    "    m1 = postFCC_med.index.values[:, None] == postFCC_med.columns.values\n",
    "    postFCC = pd.DataFrame(np.select([m1], [float('Nan')], postFCC_med), columns=postFCC_med.columns, index=postFCC_med.index)\n",
    "    postFCC_rankings= postFCC.rank(axis=1, ascending=False, na_option='keep')\n",
    "    \n",
    "    return postFCC_rankings.loc[reaction]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def bootstrap_spearman(x, y, num_bootstrap=1000, alpha=0.05):\n",
    "    n = len(x)\n",
    "    corr_list = []\n",
    "\n",
    "    # Original Spearman correlation\n",
    "    corr_original, p_value = spearmanr(x, y)\n",
    "\n",
    "    for _ in range(num_bootstrap):\n",
    "        # Generate bootstrap samples\n",
    "        indices = np.random.randint(0, n, n)\n",
    "        x_bootstrap = [x[i] for i in indices]\n",
    "        y_bootstrap = [y[i] for i in indices]\n",
    "\n",
    "        # Calculate Spearman correlation for the bootstrap sample\n",
    "        corr, _ = spearmanr(x_bootstrap, y_bootstrap)\n",
    "        corr_list.append(corr)\n",
    "\n",
    "    # Convert to numpy array for convenience\n",
    "    corr_list = np.array(corr_list)\n",
    "    \n",
    "    # Calculate the confidence intervals\n",
    "    lower_bound = np.percentile(corr_list, (alpha/2) * 100)\n",
    "    upper_bound = np.percentile(corr_list, (1 - alpha/2) * 100)\n",
    "    \n",
    "    return corr_original, p_value, lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_coefficients = []\n",
    "p_values = []\n",
    "confidence_intervals = []\n",
    "b_list = []\n",
    "for FCC in rxn_FCCs:\n",
    "    b = calculate_FCC_med_rankings(FCC)\n",
    "    b_list.append(b)\n",
    "    spearman_r, p_value, lower_ci, upper_ci = bootstrap_spearman(a.dropna(), b.dropna())\n",
    "    spearman_coefficients.append(spearman_r)\n",
    "    p_values.append(p_value)\n",
    "    confidence_intervals.append((lower_ci, upper_ci))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_df = pd.DataFrame(spearman_coefficients, columns=['r'], index=pt_labels)\n",
    "spearman_df['p-value'] = p_values\n",
    "spearman_df['lower'] = [i[0] for i in confidence_intervals]\n",
    "spearman_df['upper'] = [i[1] for i in confidence_intervals]\n",
    "spearman_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_df.to_csv('topologyC_allData_spr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(pt_labels, [i[0] for i in spearman_coefficients], alpha=0.5, color='r')\n",
    "plt.grid()\n",
    "\n",
    "for i, txt in enumerate([i[1].round(3) for i in spearman_coefficients]):\n",
    "    plt.annotate(txt, (pt_labels[i], [i[0] for i in spearman_coefficients][i]), ha='center')\n",
    "\n",
    "plt.title(\"Spearman rank correlation coefficients by perturbation strength\")\n",
    "plt.xlabel('perturbation level')\n",
    "plt.ylabel('Spearman $\\it{r}$')\n",
    "plt.ylim((0, 1.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluating top five rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_b_list = [b.sort_values().reset_index().set_index('v19') for b in b_list]\n",
    "q = pd.concat(ranked_b_list, axis=1)\n",
    "q['gt'] = a.sort_values().reset_index().set_index('v19')\n",
    "q.columns = pt_labels + ['gt']\n",
    "q = q[['gt'] + pt_labels]\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.to_csv('topologyC_allData_rankings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gayles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
